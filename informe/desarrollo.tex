\section{Desarrollo}

\subsection{Calibración}

El primer paso para comenzar el algoritmo de fotogrametría estéreo es realizar
la calibración del sistema. Cada imágen tiene una fuente de iluminación. Cada
fuente tiene una dirección en la que apunta su luz. El objetivo del paso de
calibración es poder calcular la dirección de cada fuene de iluminación.

Cada objeto tiene 12 imágenes del mismo con fuentes de iluminación con
distintas direcciones. Estas 12 fuentes de iluminación son distintas entre sí,
pero se repiten para todos los objetos. Esto hace posible que si pudiesen
calcularse las direcciones de las 12 fuentes para un objeto en particular,
entonces podrían reutilizarse para el resto de los objetos.

En este caso pueden calcularse las direcciones de las fuentes de iluminación
de uno de los objetos: la esfera. Lo que permite que esto sea posible es el
hecho de conocer con exactitud la profundidad del objeto. Al saber que el
objeto es una esfera, puede conocerse con exactitud la posición de cada
punto, sabiendo el centro y el radio de la misma siguiendo la siguiente
ecuación:

\begin{center}
$(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 = r^2$
\end{center}

donde $z_0 = 0$ ya que suponemos que está centrada respecto del eje z.
Gracias a esto, puede calcularse el vector normal a cada punto de la esfera

\begin{center}
$n = (x - x_0, y - y0, z)$
\end{center}

Sabemos, dada la naturaleza de la esfera, que el punto de mayor intensidad
lumínica será el más cercano a la fuente de iluminación, por lo que la normal
de dicho punto apuntará en dirección a la fuente. El vector opuesto a esta
normal tiene la dirección de la fuente.

Si se ejecuta este procedimiento para las 12 imágenes de la esfera, entonces
el resultado será conocer la dirección de las 12 fuentes de iluminación. Esto
permite, en los pasos siguientes del algoritmo de fotogrametría estéreo,
poder calcular la normal para cada punto, basándose en que la fuente de
iluminacion $s_i$ con $1 \leq i \leq 12$ es la misma para la imágen $i$ de
cada objeto.

\subsection{Reconstrucción del modelo 3D de los objetos digitalizados}

Una vez completada la calibración, ya se cuenta con las direcciones de
iluminación de cada caso, las cuales junto con la secuencia de imágenes de un
objeto nos proporcionarán la información necesaria para poder calcular todos
los puntos $(x,y,z)$ del modelo digitalizado y las normales de cada uno.

Puede dividirse en:

\begin{enumerate}
\item Construcción del campo normal
\item Estimación de la profundidad
\end{enumerate}

\subsubsection{Contrucción del campo normal}

En este paso se desea obtener la normal de cada punto del objeto. Para ello
se recurre a la ecuación 5 del enunciado de este trabajo práctico, que
vincula una matriz formada por 3 direcciones de fuentes de iluminación con el
vector $m$ y las intensidades del píxel en cada imágen. Esta matriz tiene 3
direcciones porque es la cantidad mínima de imágenes cuya fuente de
iluminación difiera entre sí necesaria para inferir la orientación de la
superficie.

La matriz de direcciones contiene la dirección de cada fuente de iluminación
dispuesta como fila. Una vez resuelto el sistema de ecuaciones se podrá conocer $m$ y asi mediante la siguiente ecuacion $||m|| = |I_0\rho| ||n||$, conocer el valor absoluto de $I_0\rho$. Esto permite conocer $n$ ya que tiene la misma dirección que $m$ con la diferencia de que $n$ está normalizado por ser la norma. Por lo que nos queda que $n = \frac{m}{||m||}$.

\subsubsection{Estimacion de la profundidad}

El siguiente paso es calcular la profundidad de cada pixel de la imagen. Para ello se recurre a las ecuaciones 11 y 12 del enunciado en donde se vincula a la normal de cada pixel con su profundidad. Estas ecuaciones nos permiten formar un sistema de ecuaciones como el de la ecuación 13.

Es necesario notar que $M$, la matriz de este sistema, es una matriz esparsa. La manera en la que la está dispuesta la información es la siguiente:

$M$ tiene dimensión $2n \times n$. En las primeras $n$ filas se reflejan las ecuaciones pertenecientes a $n_y$ y se forman dos diagonales contiguas que representan la vecindad vertical de los píxeles. En las segundas $n$ filas se reflejan las ecuaciones pertenecientes a $n_x$ y se forman dos diagonales separadas por el alto de la imagen que representan la vecindad horizontal de los píxeles.

Esta disposición de los datos provoca que cada columna de $M$ contenga a lo sumo 4 elementos. Nuestra implementación consiste en considerar a esta matriz como un tipo especial de matriz (la esparsa), para la cual no se tiene un arreglo bidimensional como sería el caso habitual sino un vector de hashmap, donde cada elemento del vector representa una columna. Cada hashmap contendrá entonces 4 elementos o menos. Esto permite que al querer multiplicar una columna por otra (como ocurre en el caso de querer calcular $M^tM$) no sea necesario recorrer toda la columna sino únicamente los elementos distintos de 0. Esta optimización es crucial para el desarrollo del algoritmo a nivel temporal.